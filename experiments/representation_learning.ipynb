{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:07.277822Z",
     "start_time": "2021-03-24T17:24:05.961624Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import dgl\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "\n",
    "from ddagl import graph_level_nn, graph_feature_extraction, visualization, evaluation\n",
    "\n",
    "import karateclub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:10.627326Z",
     "start_time": "2021-03-24T17:24:07.279406Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('datasets/odds/ODDS.json'):\n",
    "    from urllib import request\n",
    "    request.urlretrieve('https://zenodo.org/record/4633704/files/ODDS.json',\n",
    "                        'datasets/odds/ODDS.json')\n",
    "\n",
    "with open('datasets/odds/ODDS.json', 'r') as fp:\n",
    "    graphs = pd.Series(list(map(nx.node_link_graph, json.load(fp)['graphs'])), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:10.641822Z",
     "start_time": "2021-03-24T17:24:10.628666Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "groups = graphs.apply(lambda g: g.graph['id'])\n",
    "versions = graphs.apply(lambda g: g.graph['version'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can evaluate a feature spacing or embedding regarding its suitability for representing workflows in different versions.\n",
    "\n",
    "Generally speaking, we assume neighboring versions of a workflow to have high similarity and other versions to have low similarity. \n",
    "\n",
    "We divide an instances distances to similar workflows by the distance to neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:10.652724Z",
     "start_time": "2021-03-24T17:24:10.643052Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate_embeddings(est, X=graphs, groups=groups, nb_trials:int = 5):\n",
    "    emb_score_dicts = []\n",
    "    for random_state in range(nb_trials):\n",
    "        if isinstance(est, Pipeline):\n",
    "            est.steps[-1][-1].random_state = random_state\n",
    "        else:\n",
    "            est.random_state = random_state\n",
    "            \n",
    "        embeddings = est.fit_transform(X, groups)\n",
    "        emb_score_dicts.append(dict(gcs = group_cluster_score(groups, embeddings), \n",
    "                                           trs = triplet_ratio_score(groups, embeddings),\n",
    "                                          random_seed = random_state))\n",
    "        \n",
    "    emb_score_df = pd.DataFrame(emb_score_dicts)\n",
    "    return emb_score_df.aggregate(('mean', 'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GCN Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:10.657780Z",
     "start_time": "2021-03-24T17:24:10.653888Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "graph_emb_default_kwargs = dict(batch_size = 1000, nb_epochs = 50, random_state=42, negatives_from_batch=True,\n",
    "                               conv_cls = dgl.nn.TAGConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Raw Graph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T11:53:56.915688Z",
     "start_time": "2021-03-21T11:53:28.532244Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "glfe = graph_feature_extraction.GraphLevelFeatureExtractor(n_jobs=4)\n",
    "raw_features = glfe.fit_transform(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T11:54:16.628031Z",
     "start_time": "2021-03-21T11:54:04.494649Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7911558472972228, 0.33886920294643724)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cluster_score(groups, raw_features), triplet_ratio_score(groups, raw_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SoTA Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:24:25.646487Z",
     "start_time": "2021-03-05T10:24:25.642962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def score_kc_model(emb_fun):\n",
    "    gcs_scores, trs_scores = [], []\n",
    "    for random_seed in range(5):\n",
    "        embs = emb_fun(random_seed)\n",
    "        gcs_scores.append(group_cluster_score(groups, embs))\n",
    "        trs_scores.append(triplet_ratio_score(groups, embs))\n",
    "\n",
    "    print(round(np.mean(gcs_scores), 5), '+-', round(np.std(gcs_scores), 5), \n",
    "          round(np.mean(trs_scores), 5), '+-', round(np.std(trs_scores), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Graph2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:26:09.269049Z",
     "start_time": "2021-03-05T10:24:25.649330Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5964 +- 0.00451 0.45299 +- 0.00388\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from karateclub.utils.treefeatures import WeisfeilerLehmanHashing\n",
    "\n",
    "def get_g2v_embs(random_seed = None):\n",
    "    graph2vec = karateclub.graph_embedding.graph2vec.Graph2Vec(seed = random_seed)\n",
    "    graph2vec._set_seed()\n",
    "    documents = [WeisfeilerLehmanHashing(graph, graph2vec.wl_iterations, graph2vec.attributed, \n",
    "                                         graph2vec.erase_base_features) for graph in relevant_graphs]\n",
    "    documents = [TaggedDocument(words=doc.get_graph_features(), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
    "\n",
    "    model = Doc2Vec(documents, vector_size=graph2vec.dimensions, window=0, min_count=graph2vec.min_count,\n",
    "                    dm=0, sample=graph2vec.down_sampling, workers=graph2vec.workers, epochs=graph2vec.epochs,\n",
    "                    alpha=graph2vec.learning_rate, seed=graph2vec.seed)\n",
    "\n",
    "    return [model.docvecs[str(i)] for i, _ in enumerate(documents)]\n",
    "\n",
    "score_kc_model(get_g2v_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## FeatherGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:28:47.857693Z",
     "start_time": "2021-03-05T10:26:09.270358Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76015 +- 0.0 0.35072 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_fg_embs(random_seed):\n",
    "    fg = karateclub.graph_embedding.feathergraph.FeatherGraph(seed = random_seed)\n",
    "    fg._set_seed()\n",
    "    return [fg._calculate_feather(graph) for graph in relevant_graphs]\n",
    "\n",
    "score_kc_model(get_fg_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## GeoScattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:51:14.421377Z",
     "start_time": "2021-03-05T10:28:47.859722Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316 +- 0.0 0.33706 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_gs_embs(random_seed):\n",
    "    gs = karateclub.graph_embedding.geoscattering.GeoScattering(seed = random_seed)\n",
    "    gs._set_seed()\n",
    "    relevant_graphs_ = list(map(nx.to_undirected, relevant_graphs))\n",
    "    return [gs._calculate_geoscattering(graph) for graph in relevant_graphs_]\n",
    "\n",
    "score_kc_model(get_gs_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:54:51.459900Z",
     "start_time": "2021-03-05T10:51:14.423641Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58091 +- 0.0 0.48793 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_sf_embs(random_seed):\n",
    "    sf = karateclub.graph_embedding.sf.SF(seed = random_seed)\n",
    "    sf._set_seed()\n",
    "    relevant_graphs_ = list(map(nx.to_undirected, relevant_graphs))\n",
    "    return [sf._calculate_sf(graph) for graph in relevant_graphs_]\n",
    "\n",
    "score_kc_model(get_sf_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## FGSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T10:58:00.469620Z",
     "start_time": "2021-03-05T10:54:51.461754Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68237 +- 0.0 0.40762 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_fgsd_embs(random_seed):\n",
    "    fgsd = karateclub.graph_embedding.fgsd.FGSD(seed = random_seed)\n",
    "    fgsd._set_seed()\n",
    "    relevant_graphs_ = list(map(nx.to_undirected, relevant_graphs))\n",
    "    return [fgsd._calculate_fgsd(graph) for graph in relevant_graphs_]\n",
    "\n",
    "score_kc_model(get_fgsd_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Untrained P-GCN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:48:51.127826Z",
     "start_time": "2021-03-21T13:48:51.125297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_transformer = graph_feature_extraction.NodeLevelFeatureTransformer(use_configs=False)\n",
    "graph_emb = graph_level_nn.GroupedGraphEmbedder(**graph_emb_default_kwargs, verbose=True)\n",
    "graph_emb.nb_epochs = 0\n",
    "graph_emb_pipeline = make_pipeline(feature_transformer, graph_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:50:32.445672Z",
     "start_time": "2021-03-21T13:48:56.697210Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gcs</th>\n",
       "      <th>trs</th>\n",
       "      <th>random_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883996</td>\n",
       "      <td>0.399522</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gcs       trs  random_seed\n",
       "mean  0.883996  0.399522     2.000000\n",
       "std   0.001323  0.006897     1.581139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_embeddings(graph_emb_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Triplet Loss P-GCN Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:24:12.224752Z",
     "start_time": "2021-03-24T17:24:10.658998Z"
    },
    "hidden": true,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 110)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_transformer = graph_feature_extraction.NodeLevelFeatureTransformer(use_configs=False)\n",
    "\n",
    "X = feature_transformer.fit_transform(graphs)\n",
    "X[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T22:09:46.196917Z",
     "start_time": "2021-03-21T21:26:11.810022Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 | lr 0.01000 | loss 0.09313 | loss_std 0.03746\n",
      "epoch 001 | lr 0.00900 | loss 0.05785 | loss_std 0.01225\n",
      "epoch 002 | lr 0.00810 | loss 0.03562 | loss_std 0.01007\n",
      "epoch 003 | lr 0.00729 | loss 0.04028 | loss_std 0.00430\n",
      "epoch 004 | lr 0.00656 | loss 0.03493 | loss_std 0.00973\n",
      "epoch 005 | lr 0.00590 | loss 0.03200 | loss_std 0.01168\n",
      "epoch 006 | lr 0.00531 | loss 0.03427 | loss_std 0.01402\n",
      "epoch 007 | lr 0.00478 | loss 0.03210 | loss_std 0.00721\n",
      "epoch 008 | lr 0.00430 | loss 0.02668 | loss_std 0.00681\n",
      "epoch 009 | lr 0.00387 | loss 0.02262 | loss_std 0.00480\n",
      "epoch 010 | lr 0.00349 | loss 0.02329 | loss_std 0.00573\n",
      "epoch 011 | lr 0.00314 | loss 0.02424 | loss_std 0.00463\n",
      "epoch 012 | lr 0.00282 | loss 0.02138 | loss_std 0.00435\n",
      "epoch 013 | lr 0.00254 | loss 0.02298 | loss_std 0.00603\n",
      "epoch 014 | lr 0.00229 | loss 0.02230 | loss_std 0.00552\n",
      "epoch 015 | lr 0.00206 | loss 0.01514 | loss_std 0.00294\n",
      "epoch 016 | lr 0.00185 | loss 0.01564 | loss_std 0.00506\n",
      "epoch 017 | lr 0.00167 | loss 0.01621 | loss_std 0.00547\n",
      "epoch 018 | lr 0.00150 | loss 0.01629 | loss_std 0.00418\n",
      "epoch 019 | lr 0.00135 | loss 0.01486 | loss_std 0.00453\n",
      "epoch 020 | lr 0.00122 | loss 0.01227 | loss_std 0.00318\n",
      "epoch 021 | lr 0.00109 | loss 0.01720 | loss_std 0.00672\n",
      "epoch 022 | lr 0.00098 | loss 0.01336 | loss_std 0.00355\n",
      "epoch 023 | lr 0.00089 | loss 0.01223 | loss_std 0.00252\n",
      "epoch 024 | lr 0.00080 | loss 0.01033 | loss_std 0.00148\n",
      "epoch 025 | lr 0.00072 | loss 0.01137 | loss_std 0.00207\n",
      "epoch 026 | lr 0.00065 | loss 0.01059 | loss_std 0.00339\n",
      "epoch 027 | lr 0.00058 | loss 0.00969 | loss_std 0.00308\n",
      "epoch 028 | lr 0.00052 | loss 0.01036 | loss_std 0.00226\n",
      "epoch 029 | lr 0.00047 | loss 0.01165 | loss_std 0.00395\n",
      "epoch 030 | lr 0.00042 | loss 0.01191 | loss_std 0.00239\n",
      "epoch 031 | lr 0.00038 | loss 0.00954 | loss_std 0.00305\n",
      "epoch 032 | lr 0.00034 | loss 0.01073 | loss_std 0.00215\n",
      "epoch 033 | lr 0.00031 | loss 0.00873 | loss_std 0.00169\n",
      "epoch 034 | lr 0.00028 | loss 0.00801 | loss_std 0.00212\n",
      "epoch 035 | lr 0.00025 | loss 0.00690 | loss_std 0.00177\n",
      "epoch 036 | lr 0.00023 | loss 0.00584 | loss_std 0.00263\n",
      "epoch 037 | lr 0.00020 | loss 0.00800 | loss_std 0.00232\n",
      "epoch 038 | lr 0.00018 | loss 0.00700 | loss_std 0.00225\n",
      "epoch 039 | lr 0.00016 | loss 0.00700 | loss_std 0.00276\n",
      "epoch 040 | lr 0.00015 | loss 0.00696 | loss_std 0.00243\n",
      "epoch 041 | lr 0.00013 | loss 0.00596 | loss_std 0.00211\n",
      "epoch 042 | lr 0.00012 | loss 0.00703 | loss_std 0.00329\n",
      "epoch 043 | lr 0.00011 | loss 0.00736 | loss_std 0.00291\n",
      "epoch 044 | lr 0.00010 | loss 0.00603 | loss_std 0.00204\n",
      "epoch 045 | lr 0.00009 | loss 0.00526 | loss_std 0.00235\n",
      "epoch 046 | lr 0.00008 | loss 0.00509 | loss_std 0.00146\n",
      "epoch 047 | lr 0.00007 | loss 0.00698 | loss_std 0.00279\n",
      "epoch 048 | lr 0.00006 | loss 0.00528 | loss_std 0.00218\n",
      "epoch 049 | lr 0.00006 | loss 0.00645 | loss_std 0.00273\n",
      "epoch 000 | lr 0.01000 | loss 0.08845 | loss_std 0.02962\n",
      "epoch 001 | lr 0.00900 | loss 0.05394 | loss_std 0.01593\n",
      "epoch 002 | lr 0.00810 | loss 0.04937 | loss_std 0.01667\n",
      "epoch 003 | lr 0.00729 | loss 0.04199 | loss_std 0.01077\n",
      "epoch 004 | lr 0.00656 | loss 0.03531 | loss_std 0.00709\n",
      "epoch 005 | lr 0.00590 | loss 0.03434 | loss_std 0.01237\n",
      "epoch 006 | lr 0.00531 | loss 0.03349 | loss_std 0.01087\n",
      "epoch 007 | lr 0.00478 | loss 0.02384 | loss_std 0.00812\n",
      "epoch 008 | lr 0.00430 | loss 0.02515 | loss_std 0.00692\n",
      "epoch 009 | lr 0.00387 | loss 0.02684 | loss_std 0.00647\n",
      "epoch 010 | lr 0.00349 | loss 0.02477 | loss_std 0.00769\n",
      "epoch 011 | lr 0.00314 | loss 0.02211 | loss_std 0.00356\n",
      "epoch 012 | lr 0.00282 | loss 0.01857 | loss_std 0.00723\n",
      "epoch 013 | lr 0.00254 | loss 0.02141 | loss_std 0.00585\n",
      "epoch 014 | lr 0.00229 | loss 0.02098 | loss_std 0.00328\n",
      "epoch 015 | lr 0.00206 | loss 0.02098 | loss_std 0.00618\n",
      "epoch 016 | lr 0.00185 | loss 0.01821 | loss_std 0.00424\n",
      "epoch 017 | lr 0.00167 | loss 0.01850 | loss_std 0.00470\n",
      "epoch 018 | lr 0.00150 | loss 0.01375 | loss_std 0.00330\n",
      "epoch 019 | lr 0.00135 | loss 0.01446 | loss_std 0.00387\n",
      "epoch 020 | lr 0.00122 | loss 0.01497 | loss_std 0.00591\n",
      "epoch 021 | lr 0.00109 | loss 0.01202 | loss_std 0.00225\n",
      "epoch 022 | lr 0.00098 | loss 0.01676 | loss_std 0.00372\n",
      "epoch 023 | lr 0.00089 | loss 0.01398 | loss_std 0.00438\n",
      "epoch 024 | lr 0.00080 | loss 0.01040 | loss_std 0.00192\n",
      "epoch 025 | lr 0.00072 | loss 0.01040 | loss_std 0.00256\n",
      "epoch 026 | lr 0.00065 | loss 0.01039 | loss_std 0.00285\n",
      "epoch 027 | lr 0.00058 | loss 0.01093 | loss_std 0.00396\n",
      "epoch 028 | lr 0.00052 | loss 0.01147 | loss_std 0.00526\n",
      "epoch 029 | lr 0.00047 | loss 0.00949 | loss_std 0.00364\n",
      "epoch 030 | lr 0.00042 | loss 0.01057 | loss_std 0.00317\n",
      "epoch 031 | lr 0.00038 | loss 0.00772 | loss_std 0.00187\n",
      "epoch 032 | lr 0.00034 | loss 0.00940 | loss_std 0.00159\n",
      "epoch 033 | lr 0.00031 | loss 0.00817 | loss_std 0.00235\n",
      "epoch 034 | lr 0.00028 | loss 0.00842 | loss_std 0.00202\n",
      "epoch 035 | lr 0.00025 | loss 0.00843 | loss_std 0.00357\n",
      "epoch 036 | lr 0.00023 | loss 0.00735 | loss_std 0.00136\n",
      "epoch 037 | lr 0.00020 | loss 0.00637 | loss_std 0.00174\n",
      "epoch 038 | lr 0.00018 | loss 0.00742 | loss_std 0.00224\n",
      "epoch 039 | lr 0.00016 | loss 0.00686 | loss_std 0.00177\n",
      "epoch 040 | lr 0.00015 | loss 0.00625 | loss_std 0.00212\n",
      "epoch 041 | lr 0.00013 | loss 0.00705 | loss_std 0.00182\n",
      "epoch 042 | lr 0.00012 | loss 0.00490 | loss_std 0.00127\n",
      "epoch 043 | lr 0.00011 | loss 0.00514 | loss_std 0.00239\n",
      "epoch 044 | lr 0.00010 | loss 0.00573 | loss_std 0.00200\n",
      "epoch 045 | lr 0.00009 | loss 0.00556 | loss_std 0.00133\n",
      "epoch 046 | lr 0.00008 | loss 0.00670 | loss_std 0.00248\n",
      "epoch 047 | lr 0.00007 | loss 0.00663 | loss_std 0.00244\n",
      "epoch 048 | lr 0.00006 | loss 0.00452 | loss_std 0.00211\n",
      "epoch 049 | lr 0.00006 | loss 0.00543 | loss_std 0.00191\n",
      "epoch 000 | lr 0.01000 | loss 0.09918 | loss_std 0.03449\n",
      "epoch 001 | lr 0.00900 | loss 0.05278 | loss_std 0.02201\n",
      "epoch 002 | lr 0.00810 | loss 0.04956 | loss_std 0.01629\n",
      "epoch 003 | lr 0.00729 | loss 0.03292 | loss_std 0.00770\n",
      "epoch 004 | lr 0.00656 | loss 0.03699 | loss_std 0.00647\n",
      "epoch 005 | lr 0.00590 | loss 0.03185 | loss_std 0.00751\n",
      "epoch 006 | lr 0.00531 | loss 0.02780 | loss_std 0.00846\n",
      "epoch 007 | lr 0.00478 | loss 0.02554 | loss_std 0.00415\n",
      "epoch 008 | lr 0.00430 | loss 0.02172 | loss_std 0.00712\n",
      "epoch 009 | lr 0.00387 | loss 0.02633 | loss_std 0.00682\n",
      "epoch 010 | lr 0.00349 | loss 0.02352 | loss_std 0.00428\n",
      "epoch 011 | lr 0.00314 | loss 0.01984 | loss_std 0.00468\n",
      "epoch 012 | lr 0.00282 | loss 0.02126 | loss_std 0.00494\n",
      "epoch 013 | lr 0.00254 | loss 0.02295 | loss_std 0.00406\n",
      "epoch 014 | lr 0.00229 | loss 0.01822 | loss_std 0.00445\n",
      "epoch 015 | lr 0.00206 | loss 0.01678 | loss_std 0.00423\n",
      "epoch 016 | lr 0.00185 | loss 0.01339 | loss_std 0.00426\n",
      "epoch 017 | lr 0.00167 | loss 0.01640 | loss_std 0.00475\n",
      "epoch 018 | lr 0.00150 | loss 0.01367 | loss_std 0.00305\n",
      "epoch 019 | lr 0.00135 | loss 0.01316 | loss_std 0.00368\n",
      "epoch 020 | lr 0.00122 | loss 0.01337 | loss_std 0.00440\n",
      "epoch 021 | lr 0.00109 | loss 0.01402 | loss_std 0.00327\n",
      "epoch 022 | lr 0.00098 | loss 0.01524 | loss_std 0.00364\n",
      "epoch 023 | lr 0.00089 | loss 0.01213 | loss_std 0.00307\n",
      "epoch 024 | lr 0.00080 | loss 0.01281 | loss_std 0.00334\n",
      "epoch 025 | lr 0.00072 | loss 0.01199 | loss_std 0.00334\n",
      "epoch 026 | lr 0.00065 | loss 0.01070 | loss_std 0.00341\n",
      "epoch 027 | lr 0.00058 | loss 0.01078 | loss_std 0.00217\n",
      "epoch 028 | lr 0.00052 | loss 0.00988 | loss_std 0.00314\n",
      "epoch 029 | lr 0.00047 | loss 0.00747 | loss_std 0.00156\n",
      "epoch 030 | lr 0.00042 | loss 0.00801 | loss_std 0.00208\n",
      "epoch 031 | lr 0.00038 | loss 0.00812 | loss_std 0.00310\n",
      "epoch 032 | lr 0.00034 | loss 0.00808 | loss_std 0.00323\n",
      "epoch 033 | lr 0.00031 | loss 0.00912 | loss_std 0.00287\n",
      "epoch 034 | lr 0.00028 | loss 0.00826 | loss_std 0.00377\n",
      "epoch 035 | lr 0.00025 | loss 0.00689 | loss_std 0.00244\n",
      "epoch 036 | lr 0.00023 | loss 0.00721 | loss_std 0.00210\n",
      "epoch 037 | lr 0.00020 | loss 0.00736 | loss_std 0.00294\n",
      "epoch 038 | lr 0.00018 | loss 0.00790 | loss_std 0.00355\n",
      "epoch 039 | lr 0.00016 | loss 0.00766 | loss_std 0.00298\n",
      "epoch 040 | lr 0.00015 | loss 0.00680 | loss_std 0.00275\n",
      "epoch 041 | lr 0.00013 | loss 0.00677 | loss_std 0.00245\n",
      "epoch 042 | lr 0.00012 | loss 0.00564 | loss_std 0.00186\n",
      "epoch 043 | lr 0.00011 | loss 0.00503 | loss_std 0.00168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 044 | lr 0.00010 | loss 0.00663 | loss_std 0.00232\n",
      "epoch 045 | lr 0.00009 | loss 0.00818 | loss_std 0.00209\n",
      "epoch 046 | lr 0.00008 | loss 0.00596 | loss_std 0.00160\n",
      "epoch 047 | lr 0.00007 | loss 0.00609 | loss_std 0.00183\n",
      "epoch 048 | lr 0.00006 | loss 0.00540 | loss_std 0.00200\n",
      "epoch 049 | lr 0.00006 | loss 0.00550 | loss_std 0.00150\n",
      "epoch 000 | lr 0.01000 | loss 0.08973 | loss_std 0.03185\n",
      "epoch 001 | lr 0.00900 | loss 0.04058 | loss_std 0.01663\n",
      "epoch 002 | lr 0.00810 | loss 0.05346 | loss_std 0.01764\n",
      "epoch 003 | lr 0.00729 | loss 0.04820 | loss_std 0.01481\n",
      "epoch 004 | lr 0.00656 | loss 0.03598 | loss_std 0.00674\n",
      "epoch 005 | lr 0.00590 | loss 0.03181 | loss_std 0.00792\n",
      "epoch 006 | lr 0.00531 | loss 0.03249 | loss_std 0.01141\n",
      "epoch 007 | lr 0.00478 | loss 0.02990 | loss_std 0.00581\n",
      "epoch 008 | lr 0.00430 | loss 0.02617 | loss_std 0.00607\n",
      "epoch 009 | lr 0.00387 | loss 0.02376 | loss_std 0.00421\n",
      "epoch 010 | lr 0.00349 | loss 0.02131 | loss_std 0.00701\n",
      "epoch 011 | lr 0.00314 | loss 0.02427 | loss_std 0.00433\n",
      "epoch 012 | lr 0.00282 | loss 0.02021 | loss_std 0.00595\n",
      "epoch 013 | lr 0.00254 | loss 0.01775 | loss_std 0.00318\n",
      "epoch 014 | lr 0.00229 | loss 0.01702 | loss_std 0.00485\n",
      "epoch 015 | lr 0.00206 | loss 0.01805 | loss_std 0.00584\n",
      "epoch 016 | lr 0.00185 | loss 0.01707 | loss_std 0.00368\n",
      "epoch 017 | lr 0.00167 | loss 0.01801 | loss_std 0.00493\n",
      "epoch 018 | lr 0.00150 | loss 0.01381 | loss_std 0.00352\n",
      "epoch 019 | lr 0.00135 | loss 0.01390 | loss_std 0.00321\n",
      "epoch 020 | lr 0.00122 | loss 0.01347 | loss_std 0.00338\n",
      "epoch 021 | lr 0.00109 | loss 0.01197 | loss_std 0.00411\n",
      "epoch 022 | lr 0.00098 | loss 0.01410 | loss_std 0.00314\n",
      "epoch 023 | lr 0.00089 | loss 0.01278 | loss_std 0.00545\n",
      "epoch 024 | lr 0.00080 | loss 0.01161 | loss_std 0.00359\n",
      "epoch 025 | lr 0.00072 | loss 0.01015 | loss_std 0.00199\n",
      "epoch 026 | lr 0.00065 | loss 0.00999 | loss_std 0.00238\n",
      "epoch 027 | lr 0.00058 | loss 0.00999 | loss_std 0.00319\n",
      "epoch 028 | lr 0.00052 | loss 0.01018 | loss_std 0.00344\n",
      "epoch 029 | lr 0.00047 | loss 0.00888 | loss_std 0.00231\n",
      "epoch 030 | lr 0.00042 | loss 0.00968 | loss_std 0.00350\n",
      "epoch 031 | lr 0.00038 | loss 0.01078 | loss_std 0.00426\n",
      "epoch 032 | lr 0.00034 | loss 0.00793 | loss_std 0.00232\n",
      "epoch 033 | lr 0.00031 | loss 0.00649 | loss_std 0.00210\n",
      "epoch 034 | lr 0.00028 | loss 0.00869 | loss_std 0.00263\n",
      "epoch 035 | lr 0.00025 | loss 0.00718 | loss_std 0.00318\n",
      "epoch 036 | lr 0.00023 | loss 0.00545 | loss_std 0.00256\n",
      "epoch 037 | lr 0.00020 | loss 0.00668 | loss_std 0.00220\n",
      "epoch 038 | lr 0.00018 | loss 0.00617 | loss_std 0.00147\n",
      "epoch 039 | lr 0.00016 | loss 0.00712 | loss_std 0.00206\n",
      "epoch 040 | lr 0.00015 | loss 0.00700 | loss_std 0.00358\n",
      "epoch 041 | lr 0.00013 | loss 0.00606 | loss_std 0.00162\n",
      "epoch 042 | lr 0.00012 | loss 0.00591 | loss_std 0.00193\n",
      "epoch 043 | lr 0.00011 | loss 0.00699 | loss_std 0.00263\n",
      "epoch 044 | lr 0.00010 | loss 0.00623 | loss_std 0.00274\n",
      "epoch 045 | lr 0.00009 | loss 0.00608 | loss_std 0.00204\n",
      "epoch 046 | lr 0.00008 | loss 0.00594 | loss_std 0.00158\n",
      "epoch 047 | lr 0.00007 | loss 0.00435 | loss_std 0.00185\n",
      "epoch 048 | lr 0.00006 | loss 0.00633 | loss_std 0.00402\n",
      "epoch 049 | lr 0.00006 | loss 0.00620 | loss_std 0.00366\n",
      "epoch 000 | lr 0.01000 | loss 0.09443 | loss_std 0.03057\n",
      "epoch 001 | lr 0.00900 | loss 0.05476 | loss_std 0.01874\n",
      "epoch 002 | lr 0.00810 | loss 0.04666 | loss_std 0.01649\n",
      "epoch 003 | lr 0.00729 | loss 0.03060 | loss_std 0.00676\n",
      "epoch 004 | lr 0.00656 | loss 0.03039 | loss_std 0.01005\n",
      "epoch 005 | lr 0.00590 | loss 0.03188 | loss_std 0.00411\n",
      "epoch 006 | lr 0.00531 | loss 0.03122 | loss_std 0.00820\n",
      "epoch 007 | lr 0.00478 | loss 0.02595 | loss_std 0.00782\n",
      "epoch 008 | lr 0.00430 | loss 0.02077 | loss_std 0.00692\n",
      "epoch 009 | lr 0.00387 | loss 0.02337 | loss_std 0.00420\n",
      "epoch 010 | lr 0.00349 | loss 0.02593 | loss_std 0.00746\n",
      "epoch 011 | lr 0.00314 | loss 0.01740 | loss_std 0.00394\n",
      "epoch 012 | lr 0.00282 | loss 0.02324 | loss_std 0.00782\n",
      "epoch 013 | lr 0.00254 | loss 0.02052 | loss_std 0.00540\n",
      "epoch 014 | lr 0.00229 | loss 0.01510 | loss_std 0.00415\n",
      "epoch 015 | lr 0.00206 | loss 0.01788 | loss_std 0.00367\n",
      "epoch 016 | lr 0.00185 | loss 0.01435 | loss_std 0.00532\n",
      "epoch 017 | lr 0.00167 | loss 0.01761 | loss_std 0.00450\n",
      "epoch 018 | lr 0.00150 | loss 0.01793 | loss_std 0.00592\n",
      "epoch 019 | lr 0.00135 | loss 0.01459 | loss_std 0.00463\n",
      "epoch 020 | lr 0.00122 | loss 0.01412 | loss_std 0.00388\n",
      "epoch 021 | lr 0.00109 | loss 0.01032 | loss_std 0.00164\n",
      "epoch 022 | lr 0.00098 | loss 0.01281 | loss_std 0.00367\n",
      "epoch 023 | lr 0.00089 | loss 0.01331 | loss_std 0.00347\n",
      "epoch 024 | lr 0.00080 | loss 0.01287 | loss_std 0.00376\n",
      "epoch 025 | lr 0.00072 | loss 0.01206 | loss_std 0.00466\n",
      "epoch 026 | lr 0.00065 | loss 0.01024 | loss_std 0.00525\n",
      "epoch 027 | lr 0.00058 | loss 0.01003 | loss_std 0.00226\n",
      "epoch 028 | lr 0.00052 | loss 0.01076 | loss_std 0.00352\n",
      "epoch 029 | lr 0.00047 | loss 0.00768 | loss_std 0.00409\n",
      "epoch 030 | lr 0.00042 | loss 0.00956 | loss_std 0.00228\n",
      "epoch 031 | lr 0.00038 | loss 0.01018 | loss_std 0.00336\n",
      "epoch 032 | lr 0.00034 | loss 0.00746 | loss_std 0.00261\n",
      "epoch 033 | lr 0.00031 | loss 0.00689 | loss_std 0.00287\n",
      "epoch 034 | lr 0.00028 | loss 0.00802 | loss_std 0.00198\n",
      "epoch 035 | lr 0.00025 | loss 0.00873 | loss_std 0.00313\n",
      "epoch 036 | lr 0.00023 | loss 0.00697 | loss_std 0.00306\n",
      "epoch 037 | lr 0.00020 | loss 0.00735 | loss_std 0.00256\n",
      "epoch 038 | lr 0.00018 | loss 0.00712 | loss_std 0.00234\n",
      "epoch 039 | lr 0.00016 | loss 0.00700 | loss_std 0.00254\n",
      "epoch 040 | lr 0.00015 | loss 0.00792 | loss_std 0.00103\n",
      "epoch 041 | lr 0.00013 | loss 0.00553 | loss_std 0.00207\n",
      "epoch 042 | lr 0.00012 | loss 0.00606 | loss_std 0.00229\n",
      "epoch 043 | lr 0.00011 | loss 0.00636 | loss_std 0.00301\n",
      "epoch 044 | lr 0.00010 | loss 0.00553 | loss_std 0.00308\n",
      "epoch 045 | lr 0.00009 | loss 0.00732 | loss_std 0.00257\n",
      "epoch 046 | lr 0.00008 | loss 0.00570 | loss_std 0.00275\n",
      "epoch 047 | lr 0.00007 | loss 0.00686 | loss_std 0.00268\n",
      "epoch 048 | lr 0.00006 | loss 0.00471 | loss_std 0.00139\n",
      "epoch 049 | lr 0.00006 | loss 0.00524 | loss_std 0.00190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gcs</th>\n",
       "      <th>trs</th>\n",
       "      <th>random_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.901183</td>\n",
       "      <td>0.113135</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gcs       trs  random_seed\n",
       "mean  0.901183  0.113135     2.000000\n",
       "std   0.003752  0.003236     1.581139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_emb = graph_level_nn.GroupedGraphEmbedder(verbose=True, **graph_emb_default_kwargs)\n",
    "evaluate_embeddings(graph_emb, X = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T17:27:19.742898Z",
     "start_time": "2021-03-24T17:27:19.732381Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResGCN(\n",
       "  (conv_layers_): ModuleList(\n",
       "    (0): TAGConv(\n",
       "      (lin): Linear(in_features=330, out_features=128, bias=False)\n",
       "    )\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): TAGConv(\n",
       "      (lin): Linear(in_features=384, out_features=128, bias=False)\n",
       "    )\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): TAGConv(\n",
       "      (lin): Linear(in_features=384, out_features=128, bias=False)\n",
       "    )\n",
       "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): TAGConv(\n",
       "      (lin): Linear(in_features=384, out_features=128, bias=False)\n",
       "    )\n",
       "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): TAGConv(\n",
       "      (lin): Linear(in_features=384, out_features=128, bias=False)\n",
       "    )\n",
       "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): TAGConv(\n",
       "      (lin): Linear(in_features=384, out_features=64, bias=False)\n",
       "    )\n",
       "    (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (pooling_layer): FunctionalsPoolingLayer()\n",
       "  (aggregation_batchnorm_layer_): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (agg_layer_): Linear(in_features=256, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_emb.model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Negatives Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T23:10:46.680139Z",
     "start_time": "2021-03-21T22:18:37.833475Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 | lr 0.01000 | loss 0.10299 | loss_std 0.03922\n",
      "epoch 001 | lr 0.00900 | loss 0.04560 | loss_std 0.01143\n",
      "epoch 002 | lr 0.00810 | loss 0.04043 | loss_std 0.00675\n",
      "epoch 003 | lr 0.00729 | loss 0.02970 | loss_std 0.00896\n",
      "epoch 004 | lr 0.00656 | loss 0.02855 | loss_std 0.00581\n",
      "epoch 005 | lr 0.00590 | loss 0.02846 | loss_std 0.00659\n",
      "epoch 006 | lr 0.00531 | loss 0.02987 | loss_std 0.00628\n",
      "epoch 007 | lr 0.00478 | loss 0.02410 | loss_std 0.00514\n",
      "epoch 008 | lr 0.00430 | loss 0.02650 | loss_std 0.00848\n",
      "epoch 009 | lr 0.00387 | loss 0.02209 | loss_std 0.00533\n",
      "epoch 010 | lr 0.00349 | loss 0.02587 | loss_std 0.00565\n",
      "epoch 011 | lr 0.00314 | loss 0.02425 | loss_std 0.00550\n",
      "epoch 012 | lr 0.00282 | loss 0.02472 | loss_std 0.00829\n",
      "epoch 013 | lr 0.00254 | loss 0.02039 | loss_std 0.00882\n",
      "epoch 014 | lr 0.00229 | loss 0.01608 | loss_std 0.00585\n",
      "epoch 015 | lr 0.00206 | loss 0.01518 | loss_std 0.00422\n",
      "epoch 016 | lr 0.00185 | loss 0.01362 | loss_std 0.00342\n",
      "epoch 017 | lr 0.00167 | loss 0.01629 | loss_std 0.00506\n",
      "epoch 018 | lr 0.00150 | loss 0.01835 | loss_std 0.00525\n",
      "epoch 019 | lr 0.00135 | loss 0.01024 | loss_std 0.00364\n",
      "epoch 020 | lr 0.00122 | loss 0.01527 | loss_std 0.00393\n",
      "epoch 021 | lr 0.00109 | loss 0.01581 | loss_std 0.00378\n",
      "epoch 022 | lr 0.00098 | loss 0.01292 | loss_std 0.00179\n",
      "epoch 023 | lr 0.00089 | loss 0.01265 | loss_std 0.00307\n",
      "epoch 024 | lr 0.00080 | loss 0.01122 | loss_std 0.00240\n",
      "epoch 025 | lr 0.00072 | loss 0.01252 | loss_std 0.00456\n",
      "epoch 026 | lr 0.00065 | loss 0.01213 | loss_std 0.00177\n",
      "epoch 027 | lr 0.00058 | loss 0.01010 | loss_std 0.00241\n",
      "epoch 028 | lr 0.00052 | loss 0.01175 | loss_std 0.00581\n",
      "epoch 029 | lr 0.00047 | loss 0.00753 | loss_std 0.00216\n",
      "epoch 030 | lr 0.00042 | loss 0.01012 | loss_std 0.00165\n",
      "epoch 031 | lr 0.00038 | loss 0.00893 | loss_std 0.00295\n",
      "epoch 032 | lr 0.00034 | loss 0.00912 | loss_std 0.00218\n",
      "epoch 033 | lr 0.00031 | loss 0.00800 | loss_std 0.00266\n",
      "epoch 034 | lr 0.00028 | loss 0.00749 | loss_std 0.00292\n",
      "epoch 035 | lr 0.00025 | loss 0.00669 | loss_std 0.00272\n",
      "epoch 036 | lr 0.00023 | loss 0.00561 | loss_std 0.00137\n",
      "epoch 037 | lr 0.00020 | loss 0.00775 | loss_std 0.00240\n",
      "epoch 038 | lr 0.00018 | loss 0.00674 | loss_std 0.00175\n",
      "epoch 039 | lr 0.00016 | loss 0.00859 | loss_std 0.00478\n",
      "epoch 040 | lr 0.00015 | loss 0.00753 | loss_std 0.00236\n",
      "epoch 041 | lr 0.00013 | loss 0.00795 | loss_std 0.00321\n",
      "epoch 042 | lr 0.00012 | loss 0.00696 | loss_std 0.00291\n",
      "epoch 043 | lr 0.00011 | loss 0.00591 | loss_std 0.00173\n",
      "epoch 044 | lr 0.00010 | loss 0.00546 | loss_std 0.00203\n",
      "epoch 045 | lr 0.00009 | loss 0.00598 | loss_std 0.00210\n",
      "epoch 046 | lr 0.00008 | loss 0.00594 | loss_std 0.00226\n",
      "epoch 047 | lr 0.00007 | loss 0.00512 | loss_std 0.00261\n",
      "epoch 048 | lr 0.00006 | loss 0.00613 | loss_std 0.00250\n",
      "epoch 049 | lr 0.00006 | loss 0.00549 | loss_std 0.00105\n",
      "epoch 000 | lr 0.01000 | loss 0.08560 | loss_std 0.04211\n",
      "epoch 001 | lr 0.00900 | loss 0.03921 | loss_std 0.01503\n",
      "epoch 002 | lr 0.00810 | loss 0.04851 | loss_std 0.01428\n",
      "epoch 003 | lr 0.00729 | loss 0.04005 | loss_std 0.01036\n",
      "epoch 004 | lr 0.00656 | loss 0.03677 | loss_std 0.00662\n",
      "epoch 005 | lr 0.00590 | loss 0.03807 | loss_std 0.00857\n",
      "epoch 006 | lr 0.00531 | loss 0.03079 | loss_std 0.00502\n",
      "epoch 007 | lr 0.00478 | loss 0.02775 | loss_std 0.00650\n",
      "epoch 008 | lr 0.00430 | loss 0.02351 | loss_std 0.00537\n",
      "epoch 009 | lr 0.00387 | loss 0.02168 | loss_std 0.00283\n",
      "epoch 010 | lr 0.00349 | loss 0.02756 | loss_std 0.00895\n",
      "epoch 011 | lr 0.00314 | loss 0.01882 | loss_std 0.00582\n",
      "epoch 012 | lr 0.00282 | loss 0.01983 | loss_std 0.00651\n",
      "epoch 013 | lr 0.00254 | loss 0.01819 | loss_std 0.00425\n",
      "epoch 014 | lr 0.00229 | loss 0.01990 | loss_std 0.00370\n",
      "epoch 015 | lr 0.00206 | loss 0.01983 | loss_std 0.00570\n",
      "epoch 016 | lr 0.00185 | loss 0.01459 | loss_std 0.00283\n",
      "epoch 017 | lr 0.00167 | loss 0.01496 | loss_std 0.00493\n",
      "epoch 018 | lr 0.00150 | loss 0.01396 | loss_std 0.00359\n",
      "epoch 019 | lr 0.00135 | loss 0.01459 | loss_std 0.00582\n",
      "epoch 020 | lr 0.00122 | loss 0.01178 | loss_std 0.00388\n",
      "epoch 021 | lr 0.00109 | loss 0.01098 | loss_std 0.00287\n",
      "epoch 022 | lr 0.00098 | loss 0.01468 | loss_std 0.00250\n",
      "epoch 023 | lr 0.00089 | loss 0.01090 | loss_std 0.00295\n",
      "epoch 024 | lr 0.00080 | loss 0.01001 | loss_std 0.00322\n",
      "epoch 025 | lr 0.00072 | loss 0.01013 | loss_std 0.00207\n",
      "epoch 026 | lr 0.00065 | loss 0.00872 | loss_std 0.00254\n",
      "epoch 027 | lr 0.00058 | loss 0.01109 | loss_std 0.00370\n",
      "epoch 028 | lr 0.00052 | loss 0.00877 | loss_std 0.00390\n",
      "epoch 029 | lr 0.00047 | loss 0.00874 | loss_std 0.00234\n",
      "epoch 030 | lr 0.00042 | loss 0.00848 | loss_std 0.00240\n",
      "epoch 031 | lr 0.00038 | loss 0.00761 | loss_std 0.00361\n",
      "epoch 032 | lr 0.00034 | loss 0.00706 | loss_std 0.00261\n",
      "epoch 033 | lr 0.00031 | loss 0.00844 | loss_std 0.00504\n",
      "epoch 034 | lr 0.00028 | loss 0.00732 | loss_std 0.00203\n",
      "epoch 035 | lr 0.00025 | loss 0.00841 | loss_std 0.00219\n",
      "epoch 036 | lr 0.00023 | loss 0.00691 | loss_std 0.00177\n",
      "epoch 037 | lr 0.00020 | loss 0.00661 | loss_std 0.00217\n",
      "epoch 038 | lr 0.00018 | loss 0.00699 | loss_std 0.00203\n",
      "epoch 039 | lr 0.00016 | loss 0.00715 | loss_std 0.00264\n",
      "epoch 040 | lr 0.00015 | loss 0.00805 | loss_std 0.00289\n",
      "epoch 041 | lr 0.00013 | loss 0.00562 | loss_std 0.00143\n",
      "epoch 042 | lr 0.00012 | loss 0.00692 | loss_std 0.00232\n",
      "epoch 043 | lr 0.00011 | loss 0.00511 | loss_std 0.00212\n",
      "epoch 044 | lr 0.00010 | loss 0.00465 | loss_std 0.00180\n",
      "epoch 045 | lr 0.00009 | loss 0.00587 | loss_std 0.00157\n",
      "epoch 046 | lr 0.00008 | loss 0.00474 | loss_std 0.00119\n",
      "epoch 047 | lr 0.00007 | loss 0.00484 | loss_std 0.00166\n",
      "epoch 048 | lr 0.00006 | loss 0.00546 | loss_std 0.00244\n",
      "epoch 049 | lr 0.00006 | loss 0.00531 | loss_std 0.00193\n",
      "epoch 000 | lr 0.01000 | loss 0.09031 | loss_std 0.03922\n",
      "epoch 001 | lr 0.00900 | loss 0.07450 | loss_std 0.01797\n",
      "epoch 002 | lr 0.00810 | loss 0.04365 | loss_std 0.01262\n",
      "epoch 003 | lr 0.00729 | loss 0.03356 | loss_std 0.00861\n",
      "epoch 004 | lr 0.00656 | loss 0.03253 | loss_std 0.00833\n",
      "epoch 005 | lr 0.00590 | loss 0.04017 | loss_std 0.01197\n",
      "epoch 006 | lr 0.00531 | loss 0.02973 | loss_std 0.00769\n",
      "epoch 007 | lr 0.00478 | loss 0.02658 | loss_std 0.00762\n",
      "epoch 008 | lr 0.00430 | loss 0.02768 | loss_std 0.00648\n",
      "epoch 009 | lr 0.00387 | loss 0.02378 | loss_std 0.00514\n",
      "epoch 010 | lr 0.00349 | loss 0.02278 | loss_std 0.00669\n",
      "epoch 011 | lr 0.00314 | loss 0.02160 | loss_std 0.00647\n",
      "epoch 012 | lr 0.00282 | loss 0.01974 | loss_std 0.00474\n",
      "epoch 013 | lr 0.00254 | loss 0.01678 | loss_std 0.00409\n",
      "epoch 014 | lr 0.00229 | loss 0.01648 | loss_std 0.00315\n",
      "epoch 015 | lr 0.00206 | loss 0.01562 | loss_std 0.00257\n",
      "epoch 016 | lr 0.00185 | loss 0.01264 | loss_std 0.00339\n",
      "epoch 017 | lr 0.00167 | loss 0.01474 | loss_std 0.00407\n",
      "epoch 018 | lr 0.00150 | loss 0.01397 | loss_std 0.00252\n",
      "epoch 019 | lr 0.00135 | loss 0.01571 | loss_std 0.00346\n",
      "epoch 020 | lr 0.00122 | loss 0.01483 | loss_std 0.00341\n",
      "epoch 021 | lr 0.00109 | loss 0.01568 | loss_std 0.00302\n",
      "epoch 022 | lr 0.00098 | loss 0.01353 | loss_std 0.00316\n",
      "epoch 023 | lr 0.00089 | loss 0.01396 | loss_std 0.00540\n",
      "epoch 024 | lr 0.00080 | loss 0.01218 | loss_std 0.00211\n",
      "epoch 025 | lr 0.00072 | loss 0.01160 | loss_std 0.00323\n",
      "epoch 026 | lr 0.00065 | loss 0.01153 | loss_std 0.00305\n",
      "epoch 027 | lr 0.00058 | loss 0.01087 | loss_std 0.00327\n",
      "epoch 028 | lr 0.00052 | loss 0.01165 | loss_std 0.00385\n",
      "epoch 029 | lr 0.00047 | loss 0.01031 | loss_std 0.00298\n",
      "epoch 030 | lr 0.00042 | loss 0.00962 | loss_std 0.00316\n",
      "epoch 031 | lr 0.00038 | loss 0.00911 | loss_std 0.00322\n",
      "epoch 032 | lr 0.00034 | loss 0.00812 | loss_std 0.00084\n",
      "epoch 033 | lr 0.00031 | loss 0.00793 | loss_std 0.00277\n",
      "epoch 034 | lr 0.00028 | loss 0.00745 | loss_std 0.00292\n",
      "epoch 035 | lr 0.00025 | loss 0.00762 | loss_std 0.00291\n",
      "epoch 036 | lr 0.00023 | loss 0.00733 | loss_std 0.00197\n",
      "epoch 037 | lr 0.00020 | loss 0.00581 | loss_std 0.00223\n",
      "epoch 038 | lr 0.00018 | loss 0.00606 | loss_std 0.00154\n",
      "epoch 039 | lr 0.00016 | loss 0.00804 | loss_std 0.00169\n",
      "epoch 040 | lr 0.00015 | loss 0.00700 | loss_std 0.00209\n",
      "epoch 041 | lr 0.00013 | loss 0.00752 | loss_std 0.00232\n",
      "epoch 042 | lr 0.00012 | loss 0.00539 | loss_std 0.00089\n",
      "epoch 043 | lr 0.00011 | loss 0.00632 | loss_std 0.00203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 044 | lr 0.00010 | loss 0.00567 | loss_std 0.00277\n",
      "epoch 045 | lr 0.00009 | loss 0.00692 | loss_std 0.00281\n",
      "epoch 046 | lr 0.00008 | loss 0.00496 | loss_std 0.00146\n",
      "epoch 047 | lr 0.00007 | loss 0.00632 | loss_std 0.00228\n",
      "epoch 048 | lr 0.00006 | loss 0.00561 | loss_std 0.00230\n",
      "epoch 049 | lr 0.00006 | loss 0.00500 | loss_std 0.00147\n",
      "epoch 000 | lr 0.01000 | loss 0.08042 | loss_std 0.02995\n",
      "epoch 001 | lr 0.00900 | loss 0.04843 | loss_std 0.01860\n",
      "epoch 002 | lr 0.00810 | loss 0.04790 | loss_std 0.00865\n",
      "epoch 003 | lr 0.00729 | loss 0.03274 | loss_std 0.00600\n",
      "epoch 004 | lr 0.00656 | loss 0.03004 | loss_std 0.00260\n",
      "epoch 005 | lr 0.00590 | loss 0.02439 | loss_std 0.00449\n",
      "epoch 006 | lr 0.00531 | loss 0.03426 | loss_std 0.00620\n",
      "epoch 007 | lr 0.00478 | loss 0.03335 | loss_std 0.00952\n",
      "epoch 008 | lr 0.00430 | loss 0.03178 | loss_std 0.00796\n",
      "epoch 009 | lr 0.00387 | loss 0.03084 | loss_std 0.00805\n",
      "epoch 010 | lr 0.00349 | loss 0.02753 | loss_std 0.01121\n",
      "epoch 011 | lr 0.00314 | loss 0.02473 | loss_std 0.00684\n",
      "epoch 012 | lr 0.00282 | loss 0.01996 | loss_std 0.00434\n",
      "epoch 013 | lr 0.00254 | loss 0.02320 | loss_std 0.00455\n",
      "epoch 014 | lr 0.00229 | loss 0.02101 | loss_std 0.00869\n",
      "epoch 015 | lr 0.00206 | loss 0.01844 | loss_std 0.00358\n",
      "epoch 016 | lr 0.00185 | loss 0.01491 | loss_std 0.00381\n",
      "epoch 017 | lr 0.00167 | loss 0.01401 | loss_std 0.00429\n",
      "epoch 018 | lr 0.00150 | loss 0.01408 | loss_std 0.00302\n",
      "epoch 019 | lr 0.00135 | loss 0.01295 | loss_std 0.00361\n",
      "epoch 020 | lr 0.00122 | loss 0.01428 | loss_std 0.00604\n",
      "epoch 021 | lr 0.00109 | loss 0.01238 | loss_std 0.00275\n",
      "epoch 022 | lr 0.00098 | loss 0.01433 | loss_std 0.00223\n",
      "epoch 023 | lr 0.00089 | loss 0.01003 | loss_std 0.00342\n",
      "epoch 024 | lr 0.00080 | loss 0.00938 | loss_std 0.00265\n",
      "epoch 025 | lr 0.00072 | loss 0.01148 | loss_std 0.00501\n",
      "epoch 026 | lr 0.00065 | loss 0.01087 | loss_std 0.00256\n",
      "epoch 027 | lr 0.00058 | loss 0.00825 | loss_std 0.00230\n",
      "epoch 028 | lr 0.00052 | loss 0.01144 | loss_std 0.00360\n",
      "epoch 029 | lr 0.00047 | loss 0.00941 | loss_std 0.00155\n",
      "epoch 030 | lr 0.00042 | loss 0.00918 | loss_std 0.00330\n",
      "epoch 031 | lr 0.00038 | loss 0.00769 | loss_std 0.00153\n",
      "epoch 032 | lr 0.00034 | loss 0.00824 | loss_std 0.00216\n",
      "epoch 033 | lr 0.00031 | loss 0.00679 | loss_std 0.00199\n",
      "epoch 034 | lr 0.00028 | loss 0.00755 | loss_std 0.00291\n",
      "epoch 035 | lr 0.00025 | loss 0.00725 | loss_std 0.00187\n",
      "epoch 036 | lr 0.00023 | loss 0.00729 | loss_std 0.00203\n",
      "epoch 037 | lr 0.00020 | loss 0.00918 | loss_std 0.00230\n",
      "epoch 038 | lr 0.00018 | loss 0.00604 | loss_std 0.00281\n",
      "epoch 039 | lr 0.00016 | loss 0.00626 | loss_std 0.00164\n",
      "epoch 040 | lr 0.00015 | loss 0.00588 | loss_std 0.00277\n",
      "epoch 041 | lr 0.00013 | loss 0.00643 | loss_std 0.00320\n",
      "epoch 042 | lr 0.00012 | loss 0.00751 | loss_std 0.00243\n",
      "epoch 043 | lr 0.00011 | loss 0.00739 | loss_std 0.00257\n",
      "epoch 044 | lr 0.00010 | loss 0.00746 | loss_std 0.00109\n",
      "epoch 045 | lr 0.00009 | loss 0.00435 | loss_std 0.00120\n",
      "epoch 046 | lr 0.00008 | loss 0.00675 | loss_std 0.00294\n",
      "epoch 047 | lr 0.00007 | loss 0.00643 | loss_std 0.00278\n",
      "epoch 048 | lr 0.00006 | loss 0.00339 | loss_std 0.00162\n",
      "epoch 049 | lr 0.00006 | loss 0.00394 | loss_std 0.00149\n",
      "epoch 000 | lr 0.01000 | loss 0.08334 | loss_std 0.03171\n",
      "epoch 001 | lr 0.00900 | loss 0.05921 | loss_std 0.01848\n",
      "epoch 002 | lr 0.00810 | loss 0.04398 | loss_std 0.01248\n",
      "epoch 003 | lr 0.00729 | loss 0.04836 | loss_std 0.01050\n",
      "epoch 004 | lr 0.00656 | loss 0.03458 | loss_std 0.00731\n",
      "epoch 005 | lr 0.00590 | loss 0.03364 | loss_std 0.00509\n",
      "epoch 006 | lr 0.00531 | loss 0.02850 | loss_std 0.00650\n",
      "epoch 007 | lr 0.00478 | loss 0.02600 | loss_std 0.00619\n",
      "epoch 008 | lr 0.00430 | loss 0.02784 | loss_std 0.00546\n",
      "epoch 009 | lr 0.00387 | loss 0.02397 | loss_std 0.00385\n",
      "epoch 010 | lr 0.00349 | loss 0.02399 | loss_std 0.00522\n",
      "epoch 011 | lr 0.00314 | loss 0.02052 | loss_std 0.00659\n",
      "epoch 012 | lr 0.00282 | loss 0.01757 | loss_std 0.00581\n",
      "epoch 013 | lr 0.00254 | loss 0.02052 | loss_std 0.00563\n",
      "epoch 014 | lr 0.00229 | loss 0.01580 | loss_std 0.00456\n",
      "epoch 015 | lr 0.00206 | loss 0.02190 | loss_std 0.00599\n",
      "epoch 016 | lr 0.00185 | loss 0.01837 | loss_std 0.00391\n",
      "epoch 017 | lr 0.00167 | loss 0.01552 | loss_std 0.00418\n",
      "epoch 018 | lr 0.00150 | loss 0.01323 | loss_std 0.00357\n",
      "epoch 019 | lr 0.00135 | loss 0.01128 | loss_std 0.00312\n",
      "epoch 020 | lr 0.00122 | loss 0.01438 | loss_std 0.00281\n",
      "epoch 021 | lr 0.00109 | loss 0.01326 | loss_std 0.00464\n",
      "epoch 022 | lr 0.00098 | loss 0.01211 | loss_std 0.00477\n",
      "epoch 023 | lr 0.00089 | loss 0.01204 | loss_std 0.00291\n",
      "epoch 024 | lr 0.00080 | loss 0.01312 | loss_std 0.00449\n",
      "epoch 025 | lr 0.00072 | loss 0.00976 | loss_std 0.00271\n",
      "epoch 026 | lr 0.00065 | loss 0.00956 | loss_std 0.00232\n",
      "epoch 027 | lr 0.00058 | loss 0.01050 | loss_std 0.00394\n",
      "epoch 028 | lr 0.00052 | loss 0.01184 | loss_std 0.00288\n",
      "epoch 029 | lr 0.00047 | loss 0.01094 | loss_std 0.00327\n",
      "epoch 030 | lr 0.00042 | loss 0.00962 | loss_std 0.00182\n",
      "epoch 031 | lr 0.00038 | loss 0.00859 | loss_std 0.00248\n",
      "epoch 032 | lr 0.00034 | loss 0.00757 | loss_std 0.00174\n",
      "epoch 033 | lr 0.00031 | loss 0.00872 | loss_std 0.00280\n",
      "epoch 034 | lr 0.00028 | loss 0.00712 | loss_std 0.00349\n",
      "epoch 035 | lr 0.00025 | loss 0.00661 | loss_std 0.00212\n",
      "epoch 036 | lr 0.00023 | loss 0.00898 | loss_std 0.00327\n",
      "epoch 037 | lr 0.00020 | loss 0.00761 | loss_std 0.00307\n",
      "epoch 038 | lr 0.00018 | loss 0.00646 | loss_std 0.00246\n",
      "epoch 039 | lr 0.00016 | loss 0.00737 | loss_std 0.00256\n",
      "epoch 040 | lr 0.00015 | loss 0.00743 | loss_std 0.00281\n",
      "epoch 041 | lr 0.00013 | loss 0.00804 | loss_std 0.00236\n",
      "epoch 042 | lr 0.00012 | loss 0.00534 | loss_std 0.00144\n",
      "epoch 043 | lr 0.00011 | loss 0.00626 | loss_std 0.00229\n",
      "epoch 044 | lr 0.00010 | loss 0.00618 | loss_std 0.00264\n",
      "epoch 045 | lr 0.00009 | loss 0.00697 | loss_std 0.00213\n",
      "epoch 046 | lr 0.00008 | loss 0.00685 | loss_std 0.00198\n",
      "epoch 047 | lr 0.00007 | loss 0.00500 | loss_std 0.00197\n",
      "epoch 048 | lr 0.00006 | loss 0.00515 | loss_std 0.00208\n",
      "epoch 049 | lr 0.00006 | loss 0.00560 | loss_std 0.00232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gcs</th>\n",
       "      <th>trs</th>\n",
       "      <th>random_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.110187</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gcs       trs  random_seed\n",
       "mean  0.902468  0.110187     2.000000\n",
       "std   0.003663  0.005564     1.581139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_emb = graph_level_nn.GroupedGraphEmbedder(verbose=True, **graph_emb_default_kwargs)\n",
    "graph_emb.negatives_from_batch = False\n",
    "evaluate_embeddings(graph_emb, X=X)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "ddagl",
   "language": "python",
   "name": "ddagl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 883,
   "position": {
    "height": "905px",
    "left": "1275px",
    "right": "20px",
    "top": "123px",
    "width": "605px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
